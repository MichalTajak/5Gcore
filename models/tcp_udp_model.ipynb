{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1fa73e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('newdataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1d7ec45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(column):\n",
    "    return (\n",
    "        column.strip(' ')\n",
    "        .replace('/','_')\n",
    "        .replace(' ','_')\n",
    "        .lower()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d76f6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    column = clean_column(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "473cc253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455183, 76)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['label'] != 'label']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f271c8",
   "metadata": {},
   "source": [
    "### Ataki pogrupowane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "95cf5423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benign' 'dos' 'portscan' 'botnet' 'infiltration' 'web attack'\n",
      " 'brute force' 'heartbleed']\n",
      "  label_group  label_val\n",
      "0      benign          0\n",
      "1         dos         11\n",
      "2    portscan         12\n",
      "3    portscan         12\n",
      "4    portscan         12\n"
     ]
    }
   ],
   "source": [
    "labels = ['benign', 'ddos', 'portscan', 'botnet - attempted', 'botnet',\n",
    "          'infiltration - portscan', 'web attack - xss - attempted',\n",
    "          'web attack - brute force - attempted', 'web attack - brute force',\n",
    "          'infiltration - attempted', 'web attack - xss', 'infiltration',\n",
    "          'web attack - sql injection', 'web attack - sql injection - attempted',\n",
    "          'ftp-patator', 'ssh-patator', 'ssh-patator - attempted',\n",
    "          'ftp-patator - attempted', 'dos hulk', 'dos goldeneye',\n",
    "          'dos slowloris', 'dos slowhttptest - attempted',\n",
    "          'dos slowhttptest', 'dos slowloris - attempted', 'heartbleed',\n",
    "          'dos hulk - attempted', 'dos goldeneye - attempted']\n",
    "\n",
    "# Funkcja przypisująca słowa kluczowe do listy label_val\n",
    "def assign_label_val(label):\n",
    "    keywords = ['dos', 'ftp-patator', 'ssh-patator', 'web attack', 'botnet', 'infiltration']\n",
    "    for keyword in keywords:\n",
    "        if keyword in label:\n",
    "            if keyword == 'ftp-patator' or keyword == 'ssh-patator':\n",
    "                return 'brute force'\n",
    "            elif keyword == 'ddos':\n",
    "                return 'dos'\n",
    "            else:\n",
    "                return keyword\n",
    "    return label\n",
    "    \n",
    "df['label_group'] = df['label'].apply(assign_label_val)\n",
    "\n",
    "print(df['label_group'].unique())\n",
    "\n",
    "labels_group = df['label_group'].unique()\n",
    "label_mapping = {'benign': 0}\n",
    "label_mapping.update({label: idx + 10 for idx, label in enumerate(labels_group) if label != 'benign'})\n",
    "df['label_val'] = df['label_group'].map(label_mapping)\n",
    "\n",
    "print(df[['label_group', 'label_val']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a6b25c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "print(df['label_val'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "842ea836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1455183, 78)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a88fb900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>flow_bytes_s</th>\n",
       "      <th>flow_packets_s</th>\n",
       "      <th>fwd_packets_s</th>\n",
       "      <th>bwd_packets_s</th>\n",
       "      <th>packet_length_min</th>\n",
       "      <th>packet_length_max</th>\n",
       "      <th>packet_length_mean</th>\n",
       "      <th>average_packet_size</th>\n",
       "      <th>...</th>\n",
       "      <th>bwd_iat_min</th>\n",
       "      <th>bwd_segment_size_avg</th>\n",
       "      <th>bwd_psh_flags</th>\n",
       "      <th>bwd_rst_flags</th>\n",
       "      <th>bwd_header_length</th>\n",
       "      <th>bwd_init_win_bytes</th>\n",
       "      <th>subflow_bwd_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>label_group</th>\n",
       "      <th>label_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...</td>\n",
       "      <td>5279730.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.136422</td>\n",
       "      <td>0.757614</td>\n",
       "      <td>0.378807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5219097.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>28400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...</td>\n",
       "      <td>9575072.000000</td>\n",
       "      <td>1213.045654</td>\n",
       "      <td>1.148816</td>\n",
       "      <td>0.731065</td>\n",
       "      <td>0.417751</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11595.000000</td>\n",
       "      <td>1055.909058</td>\n",
       "      <td>1055.909058</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2898.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>29200.000000</td>\n",
       "      <td>11595.000000</td>\n",
       "      <td>ddos</td>\n",
       "      <td>dos</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37735.847656</td>\n",
       "      <td>18867.923828</td>\n",
       "      <td>18867.923828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>portscan</td>\n",
       "      <td>portscan</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133333.328125</td>\n",
       "      <td>66666.664062</td>\n",
       "      <td>66666.664062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>portscan</td>\n",
       "      <td>portscan</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26315.789062</td>\n",
       "      <td>13157.894531</td>\n",
       "      <td>13157.894531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>portscan</td>\n",
       "      <td>portscan</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               fname   flow_duration  \\\n",
       "0  /mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...  5279730.000000   \n",
       "1  /mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...  9575072.000000   \n",
       "2  /mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...       53.000000   \n",
       "3  /mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...       15.000000   \n",
       "4  /mnt/ddata/shared/anly/pcaps/out/friday/tcp-00...       76.000000   \n",
       "\n",
       "  flow_bytes_s flow_packets_s fwd_packets_s bwd_packets_s packet_length_min  \\\n",
       "0     0.000000       1.136422      0.757614      0.378807          0.000000   \n",
       "1  1213.045654       1.148816      0.731065      0.417751          0.000000   \n",
       "2     0.000000   37735.847656  18867.923828  18867.923828          0.000000   \n",
       "3     0.000000  133333.328125  66666.664062  66666.664062          0.000000   \n",
       "4     0.000000   26315.789062  13157.894531  13157.894531          0.000000   \n",
       "\n",
       "  packet_length_max packet_length_mean average_packet_size  ...  \\\n",
       "0          0.000000           0.000000            0.000000  ...   \n",
       "1      11595.000000        1055.909058         1055.909058  ...   \n",
       "2          0.000000           0.000000            0.000000  ...   \n",
       "3          0.000000           0.000000            0.000000  ...   \n",
       "4          0.000000           0.000000            0.000000  ...   \n",
       "\n",
       "      bwd_iat_min bwd_segment_size_avg bwd_psh_flags bwd_rst_flags  \\\n",
       "0  5219097.000000             0.000000      0.000000      0.000000   \n",
       "1        6.000000          2898.750000      1.000000      0.000000   \n",
       "2        0.000000             0.000000      0.000000      1.000000   \n",
       "3        0.000000             0.000000      0.000000      1.000000   \n",
       "4        0.000000             0.000000      0.000000      1.000000   \n",
       "\n",
       "  bwd_header_length bwd_init_win_bytes subflow_bwd_bytes     label  \\\n",
       "0         52.000000       28400.000000          0.000000    benign   \n",
       "1         92.000000       29200.000000      11595.000000      ddos   \n",
       "2         20.000000           0.000000          0.000000  portscan   \n",
       "3         20.000000           0.000000          0.000000  portscan   \n",
       "4         20.000000           0.000000          0.000000  portscan   \n",
       "\n",
       "  label_group label_val  \n",
       "0      benign         0  \n",
       "1         dos        11  \n",
       "2    portscan        12  \n",
       "3    portscan        12  \n",
       "4    portscan        12  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "224795f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1455183 entries, 0 to 1455186\n",
      "Data columns (total 78 columns):\n",
      " #   Column                      Non-Null Count    Dtype \n",
      "---  ------                      --------------    ----- \n",
      " 0   fname                       1455183 non-null  object\n",
      " 1   flow_duration               1455183 non-null  object\n",
      " 2   flow_bytes_s                1455183 non-null  object\n",
      " 3   flow_packets_s              1455183 non-null  object\n",
      " 4   fwd_packets_s               1455183 non-null  object\n",
      " 5   bwd_packets_s               1455183 non-null  object\n",
      " 6   packet_length_min           1455183 non-null  object\n",
      " 7   packet_length_max           1455183 non-null  object\n",
      " 8   packet_length_mean          1455183 non-null  object\n",
      " 9   average_packet_size         1455183 non-null  object\n",
      " 10  packet_length_std           1455183 non-null  object\n",
      " 11  packet_length_variance      1455183 non-null  object\n",
      " 12  flow_iat_mean               1455183 non-null  object\n",
      " 13  flow_iat_std                1455183 non-null  object\n",
      " 14  flow_iat_max                1455183 non-null  object\n",
      " 15  flow_iat_min                1455183 non-null  object\n",
      " 16  fin_flag_count              1455183 non-null  object\n",
      " 17  syn_flag_count              1455183 non-null  object\n",
      " 18  rst_flag_count              1455183 non-null  object\n",
      " 19  psh_flag_count              1455183 non-null  object\n",
      " 20  ack_flag_count              1455183 non-null  object\n",
      " 21  cwr_flag_count              1455183 non-null  object\n",
      " 22  ece_flag_count              1455183 non-null  object\n",
      " 23  down_up_ratio               1455183 non-null  object\n",
      " 24  fwd_bytes_bulk_avg          1455183 non-null  object\n",
      " 25  bwd_bytes_bulk_avg          1455183 non-null  object\n",
      " 26  fwd_packet_bulk_avg         1455183 non-null  object\n",
      " 27  bwd_packet_bulk_avg         1455183 non-null  object\n",
      " 28  fwd_bulk_rate_avg           1455183 non-null  object\n",
      " 29  bwd_bulk_rate_avg           1455183 non-null  object\n",
      " 30  active_mean                 1455183 non-null  object\n",
      " 31  active_std                  1455183 non-null  object\n",
      " 32  active_max                  1455183 non-null  object\n",
      " 33  active_min                  1455183 non-null  object\n",
      " 34  idle_mean                   1455183 non-null  object\n",
      " 35  idle_std                    1455183 non-null  object\n",
      " 36  idle_max                    1455183 non-null  object\n",
      " 37  idle_min                    1455183 non-null  object\n",
      " 38  fwd_iat_total               1455183 non-null  object\n",
      " 39  total_fwd_packet            1455183 non-null  object\n",
      " 40  total_length_of_fwd_packet  1455183 non-null  object\n",
      " 41  fwd_packet_length_min       1455183 non-null  object\n",
      " 42  fwd_packet_length_max       1455183 non-null  object\n",
      " 43  fwd_packet_length_mean      1455183 non-null  object\n",
      " 44  fwd_packet_length_std       1455183 non-null  object\n",
      " 45  fwd_iat_mean                1455183 non-null  object\n",
      " 46  fwd_iat_std                 1455183 non-null  object\n",
      " 47  fwd_iat_max                 1455183 non-null  object\n",
      " 48  fwd_iat_min                 1455183 non-null  object\n",
      " 49  fwd_segment_size_avg        1455183 non-null  object\n",
      " 50  fwd_psh_flags               1455183 non-null  object\n",
      " 51  fwd_rst_flags               1455183 non-null  object\n",
      " 52  fwd_header_length           1455183 non-null  object\n",
      " 53  fwd_init_win_bytes          1455183 non-null  object\n",
      " 54  fwd_act_data_pkts           1455183 non-null  object\n",
      " 55  fwd_seg_size_min            1455183 non-null  object\n",
      " 56  subflow_fwd_packets         1455183 non-null  object\n",
      " 57  subflow_fwd_bytes           1455183 non-null  object\n",
      " 58  bwd_iat_total               1455183 non-null  object\n",
      " 59  total_bwd_packets           1455183 non-null  object\n",
      " 60  total_length_of_bwd_packet  1455183 non-null  object\n",
      " 61  bwd_packet_length_min       1455183 non-null  object\n",
      " 62  bwd_packet_length_max       1455183 non-null  object\n",
      " 63  bwd_packet_length_mean      1455183 non-null  object\n",
      " 64  bwd_packet_length_std       1455183 non-null  object\n",
      " 65  bwd_iat_mean                1455183 non-null  object\n",
      " 66  bwd_iat_std                 1455183 non-null  object\n",
      " 67  bwd_iat_max                 1455183 non-null  object\n",
      " 68  bwd_iat_min                 1455183 non-null  object\n",
      " 69  bwd_segment_size_avg        1455183 non-null  object\n",
      " 70  bwd_psh_flags               1455183 non-null  object\n",
      " 71  bwd_rst_flags               1455183 non-null  object\n",
      " 72  bwd_header_length           1455183 non-null  object\n",
      " 73  bwd_init_win_bytes          1455183 non-null  object\n",
      " 74  subflow_bwd_bytes           1455183 non-null  object\n",
      " 75  label                       1455183 non-null  object\n",
      " 76  label_group                 1455183 non-null  object\n",
      " 77  label_val                   1455183 non-null  int64 \n",
      "dtypes: int64(1), object(77)\n",
      "memory usage: 877.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb32777",
   "metadata": {},
   "source": [
    "### Ataki nie pogrupowane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8820ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  label_val\n",
      "0    benign          0\n",
      "1      ddos         11\n",
      "2  portscan         12\n",
      "3  portscan         12\n",
      "4  portscan         12\n"
     ]
    }
   ],
   "source": [
    "labels = ['benign', 'ddos', 'portscan', 'botnet - attempted', 'botnet',\n",
    "          'infiltration - portscan', 'web attack - xss - attempted',\n",
    "          'web attack - brute force - attempted', 'web attack - brute force',\n",
    "          'infiltration - attempted', 'web attack - xss', 'infiltration',\n",
    "          'web attack - sql injection', 'web attack - sql injection - attempted',\n",
    "          'ftp-patator', 'ssh-patator', 'ssh-patator - attempted',\n",
    "          'ftp-patator - attempted', 'dos hulk', 'dos goldeneye',\n",
    "          'dos slowloris', 'dos slowhttptest - attempted',\n",
    "          'dos slowhttptest', 'dos slowloris - attempted', 'heartbleed',\n",
    "          'dos hulk - attempted', 'dos goldeneye - attempted']\n",
    "\n",
    "label_mapping = {'benign': 0}\n",
    "label_mapping.update({label: idx + 10 for idx, label in enumerate(labels) if label != 'benign'})\n",
    "df['label_val'] = df['label'].map(label_mapping)\n",
    "\n",
    "print(df[['label', 'label_val']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6b09fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['fname','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d67d35aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow_duration         float64\n",
      "flow_bytes_s          float64\n",
      "flow_packets_s        float64\n",
      "fwd_packets_s         float64\n",
      "bwd_packets_s         float64\n",
      "                       ...   \n",
      "bwd_header_length     float64\n",
      "bwd_init_win_bytes    float64\n",
      "subflow_bwd_bytes     float64\n",
      "label                  object\n",
      "label_val               int64\n",
      "Length: 76, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'label_group': 'label'}, inplace=True)\n",
    "columns_to_convert = df.columns.difference(['label', 'label_val'])\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "print(df.dtypes)\n",
    "df.to_csv('data_tcpudp_with_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d653216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[columns_to_convert]\n",
    "#y = df['label_val']\n",
    "y = df['label_group_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5babf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     976917\n",
       "11    244730\n",
       "12    158750\n",
       "14     60944\n",
       "16      6972\n",
       "13      4803\n",
       "15      2056\n",
       "17        11\n",
       "Name: label_group_val, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec47f4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ack_flag_count</th>\n",
       "      <th>active_max</th>\n",
       "      <th>active_mean</th>\n",
       "      <th>active_min</th>\n",
       "      <th>active_std</th>\n",
       "      <th>average_packet_size</th>\n",
       "      <th>bwd_bulk_rate_avg</th>\n",
       "      <th>bwd_bytes_bulk_avg</th>\n",
       "      <th>bwd_header_length</th>\n",
       "      <th>bwd_iat_max</th>\n",
       "      <th>...</th>\n",
       "      <th>psh_flag_count</th>\n",
       "      <th>rst_flag_count</th>\n",
       "      <th>subflow_bwd_bytes</th>\n",
       "      <th>subflow_fwd_bytes</th>\n",
       "      <th>subflow_fwd_packets</th>\n",
       "      <th>syn_flag_count</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>total_fwd_packet</th>\n",
       "      <th>total_length_of_bwd_packet</th>\n",
       "      <th>total_length_of_fwd_packet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "      <td>1.455183e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.446769e+01</td>\n",
       "      <td>2.849863e+05</td>\n",
       "      <td>1.528539e+05</td>\n",
       "      <td>1.124441e+05</td>\n",
       "      <td>7.518795e+04</td>\n",
       "      <td>2.601410e+02</td>\n",
       "      <td>3.336573e+06</td>\n",
       "      <td>5.678067e+03</td>\n",
       "      <td>4.341436e+02</td>\n",
       "      <td>4.463907e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.467475e+00</td>\n",
       "      <td>5.832077e-01</td>\n",
       "      <td>7.721176e+03</td>\n",
       "      <td>2.391125e+03</td>\n",
       "      <td>5.239170e+00</td>\n",
       "      <td>1.282223e+00</td>\n",
       "      <td>1.863070e+01</td>\n",
       "      <td>1.800304e+01</td>\n",
       "      <td>2.225452e+04</td>\n",
       "      <td>9.868388e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.436025e+03</td>\n",
       "      <td>1.283525e+06</td>\n",
       "      <td>8.325771e+05</td>\n",
       "      <td>7.550082e+05</td>\n",
       "      <td>4.963662e+05</td>\n",
       "      <td>3.287886e+02</td>\n",
       "      <td>1.107914e+07</td>\n",
       "      <td>3.629039e+05</td>\n",
       "      <td>2.482458e+04</td>\n",
       "      <td>1.236147e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.368429e+01</td>\n",
       "      <td>1.052516e+00</td>\n",
       "      <td>1.395804e+06</td>\n",
       "      <td>8.651319e+05</td>\n",
       "      <td>5.699252e+02</td>\n",
       "      <td>9.960687e-01</td>\n",
       "      <td>1.217109e+03</td>\n",
       "      <td>1.243690e+03</td>\n",
       "      <td>2.272185e+06</td>\n",
       "      <td>2.190873e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.800000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.950000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.600000e+01</td>\n",
       "      <td>4.508800e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>3.700000e+02</td>\n",
       "      <td>9.400000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>3.926300e+04</td>\n",
       "      <td>3.293000e+04</td>\n",
       "      <td>2.292500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.309278e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.320000e+02</td>\n",
       "      <td>4.999542e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.940000e+02</td>\n",
       "      <td>3.933333e+01</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>6.847000e+03</td>\n",
       "      <td>5.800000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.116810e+05</td>\n",
       "      <td>1.100975e+08</td>\n",
       "      <td>1.100975e+08</td>\n",
       "      <td>1.100975e+08</td>\n",
       "      <td>7.415440e+07</td>\n",
       "      <td>2.125667e+03</td>\n",
       "      <td>1.369000e+09</td>\n",
       "      <td>1.567619e+08</td>\n",
       "      <td>5.838440e+06</td>\n",
       "      <td>1.199914e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.861000e+03</td>\n",
       "      <td>1.900000e+02</td>\n",
       "      <td>6.270479e+08</td>\n",
       "      <td>5.905969e+08</td>\n",
       "      <td>2.706870e+05</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>2.919220e+05</td>\n",
       "      <td>2.895860e+05</td>\n",
       "      <td>6.554524e+08</td>\n",
       "      <td>6.396514e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ack_flag_count    active_max   active_mean    active_min    active_std  \\\n",
       "count    1.455183e+06  1.455183e+06  1.455183e+06  1.455183e+06  1.455183e+06   \n",
       "mean     3.446769e+01  2.849863e+05  1.528539e+05  1.124441e+05  7.518795e+04   \n",
       "std      2.436025e+03  1.283525e+06  8.325771e+05  7.550082e+05  4.963662e+05   \n",
       "min      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%      0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%      9.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%      1.700000e+01  3.926300e+04  3.293000e+04  2.292500e+04  0.000000e+00   \n",
       "max      5.116810e+05  1.100975e+08  1.100975e+08  1.100975e+08  7.415440e+07   \n",
       "\n",
       "       average_packet_size  bwd_bulk_rate_avg  bwd_bytes_bulk_avg  \\\n",
       "count         1.455183e+06       1.455183e+06        1.455183e+06   \n",
       "mean          2.601410e+02       3.336573e+06        5.678067e+03   \n",
       "std           3.287886e+02       1.107914e+07        3.629039e+05   \n",
       "min           0.000000e+00       0.000000e+00        0.000000e+00   \n",
       "25%           3.800000e+01       0.000000e+00        0.000000e+00   \n",
       "50%           8.950000e+01       0.000000e+00        0.000000e+00   \n",
       "75%           3.309278e+02       0.000000e+00        0.000000e+00   \n",
       "max           2.125667e+03       1.369000e+09        1.567619e+08   \n",
       "\n",
       "       bwd_header_length   bwd_iat_max  ...  psh_flag_count  rst_flag_count  \\\n",
       "count       1.455183e+06  1.455183e+06  ...    1.455183e+06    1.455183e+06   \n",
       "mean        4.341436e+02  4.463907e+06  ...    4.467475e+00    5.832077e-01   \n",
       "std         2.482458e+04  1.236147e+07  ...    3.368429e+01    1.052516e+00   \n",
       "min         0.000000e+00  0.000000e+00  ...    0.000000e+00    0.000000e+00   \n",
       "25%         1.600000e+01  3.000000e+00  ...    0.000000e+00    0.000000e+00   \n",
       "50%         9.600000e+01  4.508800e+04  ...    2.000000e+00    0.000000e+00   \n",
       "75%         2.320000e+02  4.999542e+06  ...    5.000000e+00    1.000000e+00   \n",
       "max         5.838440e+06  1.199914e+08  ...    9.861000e+03    1.900000e+02   \n",
       "\n",
       "       subflow_bwd_bytes  subflow_fwd_bytes  subflow_fwd_packets  \\\n",
       "count       1.455183e+06       1.455183e+06         1.455183e+06   \n",
       "mean        7.721176e+03       2.391125e+03         5.239170e+00   \n",
       "std         1.395804e+06       8.651319e+05         5.699252e+02   \n",
       "min         0.000000e+00       0.000000e+00         0.000000e+00   \n",
       "25%         0.000000e+00       0.000000e+00         0.000000e+00   \n",
       "50%         0.000000e+00       0.000000e+00         0.000000e+00   \n",
       "75%         2.940000e+02       3.933333e+01         3.500000e+00   \n",
       "max         6.270479e+08       5.905969e+08         2.706870e+05   \n",
       "\n",
       "       syn_flag_count  total_bwd_packets  total_fwd_packet  \\\n",
       "count    1.455183e+06       1.455183e+06      1.455183e+06   \n",
       "mean     1.282223e+00       1.863070e+01      1.800304e+01   \n",
       "std      9.960687e-01       1.217109e+03      1.243690e+03   \n",
       "min      0.000000e+00       0.000000e+00      1.000000e+00   \n",
       "25%      0.000000e+00       2.000000e+00      2.000000e+00   \n",
       "50%      2.000000e+00       4.000000e+00      6.000000e+00   \n",
       "75%      2.000000e+00       8.000000e+00      1.000000e+01   \n",
       "max      5.200000e+01       2.919220e+05      2.895860e+05   \n",
       "\n",
       "       total_length_of_bwd_packet  total_length_of_fwd_packet  \n",
       "count                1.455183e+06                1.455183e+06  \n",
       "mean                 2.225452e+04                9.868388e+03  \n",
       "std                  2.272185e+06                2.190873e+06  \n",
       "min                  0.000000e+00                0.000000e+00  \n",
       "25%                  9.800000e+01                2.000000e+01  \n",
       "50%                  3.700000e+02                9.400000e+01  \n",
       "75%                  6.847000e+03                5.800000e+02  \n",
       "max                  6.554524e+08                6.396514e+08  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2c886",
   "metadata": {},
   "source": [
    "### Test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b65add1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 12, 11, 14, 16, 13, 15, 17])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df.sample(n=500000, random_state=42)\n",
    "X = df_test[columns_to_convert]\n",
    "#y = df_test['label_val']\n",
    "y = df_test['label_group_val']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7225af",
   "metadata": {},
   "source": [
    "## Models RF + GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1d5bce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 57\u001b[0m\n\u001b[1;32m     50\u001b[0m conditional_clf \u001b[38;5;241m=\u001b[39m ConditionalClassifier(binary_clf, multiclass_clf)\n\u001b[1;32m     52\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     53\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()), \n\u001b[1;32m     54\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m'\u001b[39m, conditional_clf)       \n\u001b[1;32m     55\u001b[0m ])\n\u001b[0;32m---> 57\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     58\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     59\u001b[0m conditional_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[0;32mIn[78], line 23\u001b[0m, in \u001b[0;36mConditionalClassifier.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m X_multiclass \u001b[38;5;241m=\u001b[39m X[binary_preds \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     22\u001b[0m y_multiclass \u001b[38;5;241m=\u001b[39m y[binary_preds \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulticlass_clf\u001b[38;5;241m.\u001b[39mfit(X_multiclass, y_multiclass)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stages(\n\u001b[1;32m    784\u001b[0m     X_train,\n\u001b[1;32m    785\u001b[0m     y_train,\n\u001b[1;32m    786\u001b[0m     raw_predictions,\n\u001b[1;32m    787\u001b[0m     sample_weight_train,\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[1;32m    789\u001b[0m     X_val,\n\u001b[1;32m    790\u001b[0m     y_val,\n\u001b[1;32m    791\u001b[0m     sample_weight_val,\n\u001b[1;32m    792\u001b[0m     begin_at_stage,\n\u001b[1;32m    793\u001b[0m     monitor,\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    876\u001b[0m         )\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_stage(\n\u001b[1;32m    880\u001b[0m     i,\n\u001b[1;32m    881\u001b[0m     X,\n\u001b[1;32m    882\u001b[0m     y,\n\u001b[1;32m    883\u001b[0m     raw_predictions,\n\u001b[1;32m    884\u001b[0m     sample_weight,\n\u001b[1;32m    885\u001b[0m     sample_mask,\n\u001b[1;32m    886\u001b[0m     random_state,\n\u001b[1;32m    887\u001b[0m     X_csc\u001b[38;5;241m=\u001b[39mX_csc,\n\u001b[1;32m    888\u001b[0m     X_csr\u001b[38;5;241m=\u001b[39mX_csr,\n\u001b[1;32m    889\u001b[0m )\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:454\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    444\u001b[0m     set_huber_delta(\n\u001b[1;32m    445\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss,\n\u001b[1;32m    446\u001b[0m         y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    447\u001b[0m         raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions,\n\u001b[1;32m    448\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    449\u001b[0m     )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# TODO: Without oob, i.e. with self.subsample = 1.0, we could call\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# self._loss.loss_gradient and use it to set train_score_.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# But note that train_score_[i] is the score AFTER fitting the i-th tree.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# Note: We need the negative gradient!\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m neg_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[1;32m    455\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    456\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions,\n\u001b[1;32m    457\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# We pass sample_weights to the tree directly.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m )\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m# 2-d views of shape (n_samples, n_trees_per_iteration_) or (n_samples, 1)\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# on neg_gradient to simplify the loop over n_trees_per_iteration_.\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neg_gradient\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/_loss/loss.py:305\u001b[0m, in \u001b[0;36mBaseLoss.gradient\u001b[0;34m(self, y_true, raw_prediction, sample_weight, gradient_out, n_threads)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m gradient_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    303\u001b[0m     gradient_out \u001b[38;5;241m=\u001b[39m gradient_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcloss\u001b[38;5;241m.\u001b[39mgradient(\n\u001b[1;32m    306\u001b[0m     y_true\u001b[38;5;241m=\u001b[39my_true,\n\u001b[1;32m    307\u001b[0m     raw_prediction\u001b[38;5;241m=\u001b[39mraw_prediction,\n\u001b[1;32m    308\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    309\u001b[0m     gradient_out\u001b[38;5;241m=\u001b[39mgradient_out,\n\u001b[1;32m    310\u001b[0m     n_threads\u001b[38;5;241m=\u001b[39mn_threads,\n\u001b[1;32m    311\u001b[0m )\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gradient_out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# Definicja ConditionalClassifier\n",
    "class ConditionalClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, binary_clf, multiclass_clf):\n",
    "        self.binary_clf = binary_clf\n",
    "        self.multiclass_clf = multiclass_clf\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.binary_clf.fit(X, y)\n",
    "        binary_preds = self.binary_clf.predict(X)\n",
    "        X_multiclass = X[binary_preds != 0]\n",
    "        y_multiclass = y[binary_preds != 0]\n",
    "        self.multiclass_clf.fit(X_multiclass, y_multiclass)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        binary_preds = self.binary_clf.predict(X)\n",
    "        final_preds = np.copy(binary_preds)\n",
    "        X_multiclass = X[binary_preds != 0]\n",
    "        multiclass_preds = self.multiclass_clf.predict(X_multiclass)\n",
    "        final_preds[binary_preds != 0] = multiclass_preds\n",
    "        \n",
    "        return final_preds\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "binary_clf = RandomForestClassifier(\n",
    "    max_depth=20,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=500,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "multiclass_clf = GradientBoostingClassifier(n_estimators=100)  \n",
    "\n",
    "conditional_clf = ConditionalClassifier(binary_clf, multiclass_clf)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('clf', conditional_clf)       \n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "conditional_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cfm = cf_matrix / np.sum(cf_matrix, axis=1)[:, None]\n",
    "df_cm = pd.DataFrame(cfm, index=np.unique(y), columns=np.unique(y))\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print('cm_diag', np.diag(df_cm))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2f', cbar=True, \n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix Heatmap for Conditional Classifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc97ac",
   "metadata": {},
   "source": [
    "## Models GAN + GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d937f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/500], Loss: 0.6558\n",
      "Epoch [100/500], Loss: 0.5922\n",
      "Epoch [150/500], Loss: 0.4731\n",
      "Epoch [200/500], Loss: 0.3441\n",
      "Epoch [250/500], Loss: 0.2314\n",
      "Epoch [300/500], Loss: 0.1612\n",
      "Epoch [350/500], Loss: 0.1240\n",
      "Epoch [400/500], Loss: 0.1037\n",
      "Epoch [450/500], Loss: 0.0909\n",
      "Epoch [500/500], Loss: 0.0816\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Definicja Discriminatora\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Definicja ConditionalClassifier\n",
    "class ConditionalClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, binary_clf, multiclass_clf, scaler):\n",
    "        self.binary_clf = binary_clf\n",
    "        self.multiclass_clf = multiclass_clf\n",
    "        self.scaler = scaler\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = self.scaler.transform(X)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor((y > 0).astype(int).values, dtype=torch.float32).view(-1, 1)\n",
    "        self.binary_clf.train()\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.binary_clf.parameters(), lr=0.0001)\n",
    "        epochs = 500\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            outputs = self.binary_clf(X_tensor)\n",
    "            loss = criterion(outputs, y_tensor)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            binary_preds = (self.binary_clf(X_tensor).numpy() > 0.5).astype(int).flatten()\n",
    "            \n",
    "        mask = binary_preds != 0\n",
    "        X_multiclass = X[binary_preds != 0,:]\n",
    "        y_multiclass = y[binary_preds != 0]\n",
    "        self.multiclass_clf.fit(X_multiclass, y_multiclass)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.scaler.transform(X)\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            binary_preds = (self.binary_clf(X_tensor).numpy() > 0.5).astype(int).flatten()\n",
    "        \n",
    "        X_multiclass = X[binary_preds != 0]\n",
    "        multiclass_preds = self.multiclass_clf.predict(X_multiclass)\n",
    "        final_preds = np.copy(binary_preds)\n",
    "        final_preds[binary_preds != 0] = multiclass_preds       \n",
    "        return final_preds \n",
    "    \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "discriminator = Discriminator(input_dim)\n",
    "multiclass_clf = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "conditional_clf = ConditionalClassifier(discriminator, multiclass_clf, scaler)\n",
    "\n",
    "conditional_clf.fit(X_train, y_train)\n",
    "y_pred = conditional_clf.predict(X_test)\n",
    "\n",
    "conditional_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Conditional Classifier Accuracy:\", conditional_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be13efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cfm = cf_matrix / np.sum(cf_matrix, axis=1)[:, None]\n",
    "df_cm = pd.DataFrame(cfm, index=np.unique(y_test), columns=np.unique(y_test))\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print('cm_diag', np.diag(df_cm))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2f', cbar=True, \n",
    "            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix Heatmap for Conditional Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a742b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'benign' 'dos' 'portscan' 'botnet' 'infiltration' 'web attack'\n",
    " 'brute force' 'heartbleed'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
